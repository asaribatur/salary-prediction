{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "956c8f06",
   "metadata": {},
   "source": [
    "# KÜTÜPHANE VE AYARLAMALAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e285a51b-b1d5-4bba-a551-e82483a680ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ################# I M P O R T S ################# #\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import joblib\n",
    "\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingClassifier\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import cross_validate, train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV, validation_curve, RepeatedKFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "\n",
    "# ################# S E T T I N G S ################# #\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62178d12-cb7e-4d6b-8687-65a3637124a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r\"data/step6_encoded_remastered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075b3564-fe94-471a-a3b1-b27a255d8114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rasgele 8 gözlem seçip gözlemleyelim\n",
    "df.sample(8).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00b0e8-5651-4b47-8613-e9f38fb4377f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tüm değişkenleri görelim\n",
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86340b78-13c6-4442-baee-d90cc735e232",
   "metadata": {},
   "source": [
    "# MODEL SEÇİMİ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2a6d65b",
   "metadata": {},
   "source": [
    "## Modeller Hakkında Bilgi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "699b5894",
   "metadata": {},
   "source": [
    "**Linear Regression Methods**\n",
    "\n",
    "If we have very few features on a data-set and the score is poor for both training and test set then it’s a problem of under-fitting. On the other hand if we have large number of features and test score is relatively poor than the training score then it’s the problem of over-generalization or over-fitting. Ridge and Lasso regression are some of the simple techniques to reduce model complexity and prevent over-fitting which may result from simple linear regression.\n",
    "\n",
    "**Ridge Regression :** In ridge regression, the cost function is altered by adding a penalty equivalent to square of the magnitude of the coefficients.\n",
    "\n",
    "**Lasso Regression :** Lasso stands forleast absolute shrinkage and selection operator. The only difference from Ridge is instead of taking the square of the coefficients, magnitudes are taken into account. This type of regularization (L1) can lead to zero coefficients i.e. some of the features are completely neglected for the evaluation of output. So Lasso regression not only helps in reducing over-fitting but it can help us in feature selection.\n",
    "\n",
    "**Elastic Net regression**: The elastic net algorithm uses a weighted combination of L1 and L2 regularization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "db156c68",
   "metadata": {},
   "source": [
    "## Model Başarı Metriklerini Karşılaştırma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0bc167d3",
   "metadata": {},
   "source": [
    "**İlk olarak bağımlı ve bağımsız değişkenlerimizi belirliyoruz.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ee47b35-2cf3-4afe-8579-0642662ea716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dışarıda tutacağımız değişkenler\n",
    "ignored_vals = [\"SALARY_AVG_TL\"]\n",
    "\n",
    "# Bağımlı değişkeni dışarıda bırakıp geride kalan tüm (bağımsız) değişkenleri bir df'e atayalım\n",
    "X = df.drop(ignored_vals, axis=1)\n",
    "\n",
    "# Bağımlı değişkenimizi ayrı bir df'e atayalım\n",
    "y = df[[\"SALARY_AVG_TL\"]].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a42d51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LEVEL', 'EXPERIENCE', 'POSITION_CTO', 'POSITION_DATA SCIENTIST', 'POSITION_DATABASE ADMIN', 'POSITION_DEVOPS ENGINEER', 'POSITION_EMBEDDED SOFTWARE DEVELOPER', 'POSITION_FRONT-END DEVELOPER', 'POSITION_FULL STACK DEVELOPER', 'POSITION_GAME DEVELOPER', 'POSITION_MOBILE APPLICATION DEVELOPER', 'POSITION_OTHER', 'POSITION_QA / TEST AUTOMATION DEVELOPER', 'POSITION_SOFTWARE ARCHITECT', 'POSITION_SOFTWARE DEVELOPMENT MANAGER', 'POSITION_TEAM / TECH LEAD', 'GENDER_Kadın', 'COMPANY_Dijital / Reklam Ajansı', 'COMPANY_E-Ticaret', 'COMPANY_Fintech / Finans', 'COMPANY_Kurumsal', 'COMPANY_Outsource', 'COMPANY_Oyun', 'COMPANY_Startup', 'COMPANY_Yazılım & Teknoloji', 'WORK_TYPE_Geçici Remote', 'WORK_TYPE_Hibrit', 'WORK_TYPE_Ofis', 'WORK_TYPE_Remote', 'CITY_yurt_ici', 'CURRENCY_GBP', 'CURRENCY_TRY', 'CURRENCY_USD'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Doğrulama\n",
    "X.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5fc90f56",
   "metadata": {},
   "source": [
    "It is always a good idea to seperate the test set and training set, even while using cross_val_score. The reason behind this is knowledge leaking. It basically means that when you use both training and test sets, you are leaking information from test set into your model, thereby making your model biased, leading to incorrect predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72a57d3a",
   "metadata": {},
   "source": [
    "**Farklı modellerin başarı/hata skorlarına bakmak için ilk önce veri setini iki parçaya ayırmak daha doğru bir yaklaşım olacaktır.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc5d4f2a-f990-4c93-bdc4-c306af586a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90487f35-8afd-4c31-ad9a-f2ae5e7477c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BİRDEN ÇOK MODELİN R KARE DEGERLERİNE BAKALIM\n",
    "models = [('LR', LinearRegression()),\n",
    "          (\"Ridge\", Ridge()),\n",
    "          (\"Lasso\", Lasso()),\n",
    "          (\"ElasticNet\", ElasticNet()),\n",
    "          ('KNN', KNeighborsRegressor()),\n",
    "          ('CART', DecisionTreeRegressor()),\n",
    "          ('RF', RandomForestRegressor()),\n",
    "          ('SVR', SVR()),\n",
    "          ('GBM', GradientBoostingRegressor()),\n",
    "          (\"XGBoost\", XGBRegressor(objective='reg:squarederror')),\n",
    "         # (\"CatBoost\", CatBoostRegressor(verbose=False)), Çok uzun sürdüğü için ilk etapta çalışmasını istemiyoruz\n",
    "          (\"LightGBM\", LGBMRegressor())]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a32cee0",
   "metadata": {},
   "source": [
    "### 5 Katlı CV R Kare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7af1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsqr_scr = list()\n",
    "\n",
    "for name, regressor in models:\n",
    "    rsqr = np.mean(cross_val_score(regressor,\n",
    "                                   X_train,\n",
    "                                   y_train,\n",
    "                                   cv=5,\n",
    "                                   scoring=\"r2\")) # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    rsqr_scr.append(round(rsqr, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6adea296",
   "metadata": {},
   "source": [
    "### 5 Katlı CV RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d840d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_scr = list()\n",
    "\n",
    "for name, regressor in models:\n",
    "    rmse = np.mean((-1) * cross_val_score(regressor,\n",
    "                                            X_train,\n",
    "                                            y_train,\n",
    "                                            cv=5,\n",
    "                                            scoring='neg_root_mean_squared_error')) # https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "    rmse_scr.append(round(rmse, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ffc09afb",
   "metadata": {},
   "source": [
    "### Sonuçlar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5314815",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [name for name, regressor in models]\n",
    "scr_dict = {\"R SQUARE\": rsqr_scr, \"RMSE\": rmse_scr}\n",
    "mod_comp_df = pd.DataFrame(data=scr_dict, index=model_names)\n",
    "mod_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00205b5-12ab-4e17-9769-dca57a70255a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SALARY_AVG_TL'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e024c3-7c3e-4d7e-b72a-e4cb90f937e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SALARY_AVG_TL'].std()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0983e99",
   "metadata": {},
   "source": [
    "# MODEL OLUŞTURMA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd5da3a0",
   "metadata": {},
   "source": [
    "### SEÇİLEN ALGORİTMALAR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4d00d31",
   "metadata": {},
   "source": [
    "- Linear Regression\n",
    "- Catboost Regressor\n",
    "- Gradient Boosting Regressor\n",
    "- LGBM Regressor\n",
    "- (Ek) Random Forests Regressor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "721ace86",
   "metadata": {},
   "source": [
    "### MODEL UYGULAMA İŞLEM BASAMAKLARI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aec23e6e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "1. Model kurma\n",
    "2. İlk model başarı değerlendirme\n",
    "3. Hiperparametre optimizasyonu\n",
    "4. Final model başarı değerlendirme\n",
    "6. Tahmin\n",
    "5. Sonuç"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f808604d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## A) LINEAR REGRESSION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2b38cb99",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Model Kurma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509933c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Birden çok bağımsız değişkenimiz olduğundan Çoklu Doğrusal Regresyon yöntemini kullanmalıyız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ee749",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Modelimizi kuralım\n",
    "reg_model = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063a59a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sabit (b = bias = beta = intercept) -> Doğrunun y eksenini kestiği nokta\n",
    "reg_model.intercept_[0] # Döndürdüğü tek elemanlı diziden ilk elemanı göster; 75839.29781"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d37fac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Katsayılar - coefficients (w - weights)\n",
    "reg_model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b06c77cf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 2. Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e658f1",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Veri setinden rasgele bir gözlem birimi seçelim\n",
    "ran_obs = df.sample(1)\n",
    "ran_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c611d26",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hedef değişken hariç diğerlerine ait gözlem değerlerini alalım\n",
    "ran_obs_ind = ran_obs.loc[:, df.columns != 'SALARY_AVG_TL']\n",
    "ran_obs_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0858d36",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bu gözlem birimi için tahmin işlemi yapalım\n",
    "pred_val = int(reg_model.predict(ran_obs_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cc080",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sonuçları mukayese edelim\n",
    "print(f\"ACTUAL VALUE\\t\\t: {int(ran_obs['SALARY_AVG_TL'].values)}\")\n",
    "print(f\"PREDICTED VALUE\\t\\t: {pred_val}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8076696f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3. Model Başarı Değerlendirme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d77858e5",
   "metadata": {},
   "source": [
    "R Square/Adjusted R Square is better used to explain the model to other people because you can explain the number as a percentage of the output variability. MSE, RMSE, or MAE are better be used to compare performance between different regression models. Personally, I would prefer using RMSE and I think Kaggle also uses it to assess the submission. However, it makes total sense to use MSE if the value is not too big and MAE if you do not want to penalize large prediction errors.\n",
    "\n",
    "Adjusted R square is the only metric here that considers the overfitting problem. R Square has a direct library in Python to calculate but I did not find a direct library to calculate Adjusted R square except using the statsmodel results. If you really want to calculate Adjusted R Square, you can use statsmodel or use its mathematic formula directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56beb9a0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train RMSE\n",
    "y_pred = reg_model.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7094550",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAIN R-Kare\n",
    "reg_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c80ae",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test RMSE; Train seti üzerinden kurduğumuz modeli test seti üzerinde kullanıp ort hata miktarına bakıyoruz\n",
    "y_pred = reg_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "40c1ab80",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Test hatası train hatasından beklenildiği gibi daha yüksek çıktı.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3933c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TEST R-Kare\n",
    "reg_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601f5db",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**R Square/Adjusted R Square**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb732b2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "R Square is calculated by the sum of squared of prediction error divided by the total sum of the square which replaces the calculated prediction with mean. R Square value is between 0 to 1 and a bigger value indicates a better fit between prediction and actual value.\n",
    "\n",
    "R Square is a good measure to determine how well the model fits the dependent variables. However, it does not take into consideration of overfitting problem. If your regression model has many independent variables, because the model is too complicated, it may fit very well to the training data but performs badly for testing data. That is why Adjusted R Square is introduced because it will penalize additional independent variables added to the model and adjust the metric to prevent overfitting issues."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3db21808",
   "metadata": {},
   "source": [
    "Modelimizin çok sayıda bağımsız değişkeni yok. Ayrıca overfitting de sözkonusu değil. Ancak yine de düzeltilmiş R-Kare değerine de bakalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_addC = sm.add_constant(X)\n",
    "model = sm.OLS(y, X_addC).fit()\n",
    "\n",
    "# display adjusted R-squared\n",
    "print('Adjusted R Square\\t: %.5f' % model.rsquared_adj)   # 0.63904\n",
    "print('R Square\\t\\t: %.5f' % model.rsquared)   # 0.64133"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e41b4880",
   "metadata": {},
   "source": [
    "### 5 Katlı CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8366e944",
   "metadata": {},
   "source": [
    "**R Kare**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8cf75a2d",
   "metadata": {},
   "source": [
    "Az önce belirttiğimiz gibi, train - test şeklinde veri setinin ikiye ayrılması model başarı skorunun doğruluğunu tehlikeye atabilir. Bu riski bertaraf etmek için K-folded Cross Validation yöntemiyle R-Kare metriğimizi hesaplayacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e0fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(reg_model,\n",
    "                        X_test,    # Bağımsız değişkenler\n",
    "                        y_test,         # Bağımlı değişken\n",
    "                        cv=5,\n",
    "                        scoring='r2'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "963b81f1",
   "metadata": {},
   "source": [
    "Ortalama R-Kare değeri %64 çıktı. Daha önceki değerden biraz daha düşük. Ancak fark çok az da olsa burada elde edileni baz almak daha isabetli olacaktır."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2cc64042",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**RMSE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023bce42",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- N Katlı Cross Validation ile modelimizin ortalama RMSE değerine bakacağız.\n",
    "- CV negatif değerler döndüreceği için - ile çarpıp değerleri pozitif yaptık\n",
    "- cross_val_score normalde MSE değerleri verir. RMSE istediğimiz için elde edilen değerlerin kareköklerini aldık.\n",
    "- Ayrıca veri setimiz zaten küçük olduğundan iki parçaya ayırmamayı tercih ettik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6634ec",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(np.sqrt(-cross_val_score(reg_model,\n",
    "                                 X,         # Bağımsız değişkenler\n",
    "                                 y,         # Bağımlı değişken\n",
    "                                 cv=5,\n",
    "                                 scoring=\"neg_mean_squared_error\")))\n",
    "# 17828.1512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac14b90",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**MAE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6cd05a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_absolute_error(y_test, y_pred)     # 8470.20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cd0f5103",
   "metadata": {},
   "source": [
    "### 4. Hiperparametre Optimizasyonu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dfbcbd4a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Hyper-parameters by definition are input parameters which are necessarily required by an algorithm to learn from data.\n",
    "\n",
    "For basic straight line linear regression, there are no hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_model.get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c68d3b2",
   "metadata": {},
   "source": [
    "Bu nedenle optimizasyon işlemi için daha önce oluşturduğumuz doğrusal regresyon modelimizi kullanamayız. Onun yerine yine birer LR yöntemi olan **Ridge()** ya da **Lasso()** yöntemlerini kullanabiliriz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b49907",
   "metadata": {},
   "outputs": [],
   "source": [
    "las_model = Lasso()\n",
    "las_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5b6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rid_model = Ridge()\n",
    "rid_model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bcace94",
   "metadata": {},
   "source": [
    "### 5. Model Başarı Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a415ac",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train RMSE\n",
    "y_pred = las_model.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cde87a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TRAIN R-Kare\n",
    "las_model.score(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ab6e5333",
   "metadata": {},
   "source": [
    "**Lasso() Test Seti**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(las_model,\n",
    "                        X_test,              # Bağımsız değişkenler\n",
    "                        y_test,              # Bağımlı değişken\n",
    "                        cv=5,\n",
    "                        scoring='r2'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "460e4ce0",
   "metadata": {},
   "source": [
    "**Ridge() Test Seti**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(rid_model,\n",
    "                        X_test,              # Bağımsız değişkenler\n",
    "                        y_test,              # Bağımlı değişken\n",
    "                        cv=5,\n",
    "                        scoring='r2'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8173e223",
   "metadata": {},
   "source": [
    "### 6. SONUÇ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "de7d06b2",
   "metadata": {},
   "source": [
    "Standart doğrusal modelimizi geliştirmek için kullandığımız Lasso ve Ridge yöntemleri model başarımızı artırma konusunda pek yardımcı olamadı.\n",
    "\n",
    "Diğer yöntemlere de bakmamız gerekiyor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c1f032d6",
   "metadata": {},
   "source": [
    "## B) CATBOOST REGRESSOR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ca712cf6",
   "metadata": {},
   "source": [
    "### 1. Model Kurma"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd8a46f1",
   "metadata": {},
   "source": [
    "**Setup the Data for regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e0135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bağımlı değişkeni dışarıda bırakıp geride kalan tüm (bağımsız) değişkenleri bir df'e atayalım\n",
    "X = df.drop(\"SALARY_AVG_TL\", axis=1)\n",
    "\n",
    "# Bağımlı değişkenimizi ayrı bir df'e atayalım\n",
    "y = df[[\"SALARY_AVG_TL\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac72661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setini train (%80) ve test (%20) şeklinde iki parçaya ayır.\n",
    "# Her çalıştırdığımızda aynı değerleri almak için random_state değerini set ettik.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1e2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we are using CatBoostRegressor as a Machine Learning model to fit the data.\n",
    "model_CBR = CatBoostRegressor(verbose=False)\n",
    "model_CBR.fit(X_train, y_train)\n",
    "\n",
    "# CatBoost metodu fit edilen bir modelde hiperparametre kabul etmiyor. Onun için ikinci bir model kurup fit etmeden bırakıyorum\n",
    "model_CBR_new = CatBoostRegressor(verbose=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "83e7dea4",
   "metadata": {},
   "source": [
    "### 2. İlk Model İçin Başarı Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb288d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have predicted the output by passing X_test and also stored real target in expected_y.\n",
    "expected_y  = y_test                   \n",
    "predicted_y = model_CBR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have printed r2 score and mean squared log error for the Regressor.\n",
    "print(\"R SQUARE:\", r2_score(expected_y, predicted_y))\n",
    "print(\"MSE\\t:\", np.sqrt(mean_squared_error(expected_y, predicted_y)))\n",
    "\n",
    "# R SQUARE  : 0.5632\n",
    "# MSE\t    : 20349.9524"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8563ce97",
   "metadata": {},
   "source": [
    "### 3. Hiperparametre Optimizasyonu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "256b0ce2",
   "metadata": {},
   "source": [
    "Modeli fit ettikten sonra parametrelerini değiştirmemize izin vermiyor.\n",
    "Bunun için en iyi parametreleri bulup bu değerlerle modelimizi kuracağız."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f01cdbce",
   "metadata": {},
   "source": [
    "*Model iyileştirme için kullanacağımız parametrelerin varsayılan değerleri:*\n",
    "- 'depth': 6,\n",
    "- 'learning_rate': 0.05,\n",
    "- 'iterations': 1000\n",
    "\n",
    "Her bir parametre için bu değerleri de içeren ve bu değerlere yakın parametre listeleri oluşturup en iyilerini bulmaya çalışacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c78468",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'depth'         : [4, 8, 10, 12],\n",
    "              'learning_rate' : [0.01, 0.05, 0.1],\n",
    "              'iterations'    : [5, 10, 20, 30, 50, 100, 500, 1000]\n",
    "             }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d6963f6",
   "metadata": {},
   "source": [
    "**Using GridSearchCV and Printing Results**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2bdef38",
   "metadata": {},
   "source": [
    "Before using GridSearchCV, lets have a look on the important parameters.\n",
    "\n",
    "- estimator: In this we have to pass the models or functions on which we want to use GridSearchCV\n",
    "- param_grid: Dictionary or list of parameters of models or function in which GridSearchCV have to select the best.\n",
    "- Scoring: It is used as a evaluating metric for the model performance to decide the best hyperparameters, if not especified then it uses estimator score.\n",
    "- cv : In this we have to pass a interger value, as it signifies the number of splits that is needed for cross validation. By default is set as five.\n",
    "- n_jobs : This signifies the number of jobs to be run in parallel, -1 signifies to use all processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5ded94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an object grid_GBC for GridSearchCV and fitting the dataset i.e X and y\n",
    "grid = GridSearchCV(estimator=model_CBR,    # Model object\n",
    "                    param_grid = parameters,\n",
    "                    cv = 2,     # Number of folds for Cross Validation \n",
    "                    n_jobs=-1)  # Use all processors to maximize performance\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecd2075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are using print statements to print the results. It will give the values of hyperparameters as a result.\n",
    "print(\" Results from Grid Search \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64602dd7",
   "metadata": {},
   "source": [
    "**Best Parameters**\n",
    "\n",
    "- 'depth': 10,\n",
    "- 'iterations': 5,\n",
    "- 'learning_rate': 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9d5c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# İkinci modele en iyi parametre değerlerini verelim\n",
    "model_CBR_new.set_params(**grid.best_params_, random_state=17).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Şimdi fit edebiliriz\n",
    "model_CBR_new.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c20c51a1",
   "metadata": {},
   "source": [
    "### 3. Final Model Başarı Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb288d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have predicted the output by passing X_test and also stored real target in expected_y.\n",
    "expected_y  = y_test                   \n",
    "predicted_y = model_CBR_new.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2e94da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have printed r2 score and mean squared log error for the Regressor.\n",
    "print(\"R SQUARE:\", r2_score(expected_y, predicted_y))\n",
    "print(\"MSE\\t:\", np.sqrt(mean_squared_error(expected_y, predicted_y)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ecd1ba20",
   "metadata": {},
   "source": [
    "### 4. Sonuç"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccd25a0f",
   "metadata": {},
   "source": [
    "CatBoostRegressor modelinin [sitesinde](https://catboost.ai) de belirtildiği gibi kategorik değişkenleri One Hot Encoding yöntemiyle sayısal değerlere dönüştürmek iyi sonuçlar vermeyebiliyor. Burada hiperparametre optimizasyonu yaptıktan sonra başarı skoru ciddi bir şekilde azalıp hata değeri arttı. Dolayısıyla bu yöntemi kullanmak istiyorsak modelin ilk halini almalıyız."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ea87215",
   "metadata": {},
   "source": [
    "### Variable Importance Plot for CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96be4a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance = model_CBR.feature_importances_.argsort()\n",
    "plt.barh(df.columns[sorted_feature_importance], \n",
    "        model_CBR.feature_importances_[sorted_feature_importance], \n",
    "        color='turquoise')\n",
    "plt.xlabel(\"CatBoost Feature Importance\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "771b2e81",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## C) GRADIENT BOOSTING REGRESSOR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc2d86b8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Model Kurma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafa6f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli train seti üzerinde kuralım\n",
    "gbr_model = GradientBoostingRegressor()\n",
    "gbr_model.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ec86a13",
   "metadata": {},
   "source": [
    "### 2. İlk Model Başarısını Değerlendirme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ec86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RMSE\n",
    "y_pred = gbr_model.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786ec86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN R-Kare\n",
    "gbr_model.score(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a9272d72",
   "metadata": {},
   "source": [
    "*R Kare değeri gayet iyi. Ancak bu train seti puanı. Bir de test seti için skorlara bakalım.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f46073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test RMSE; Train seti üzerinden kurduğumuz modeli test seti üzerinde kullanıp ort hata miktarına bakıyoruz\n",
    "y_pred = gbr_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "270952eb",
   "metadata": {},
   "source": [
    "*Beklenileceği üzere, RMSE değeri train setine göre artmış*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34401b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(gbr_model,\n",
    "                        X_test,              # Bağımsız değişkenler\n",
    "                        y_test,              # Bağımlı değişken\n",
    "                        cv=5,\n",
    "                        scoring='r2'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7b0d112",
   "metadata": {},
   "source": [
    "*R-Kare değeri train setine göre çok düştü!*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "37ca852f",
   "metadata": {},
   "source": [
    "### 3. Hiperparametre Optimizasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19721e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varsayılan değerler\n",
    "gbr_model.get_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcddd60c",
   "metadata": {},
   "source": [
    "Modelimizin tahmin başarısını artırmak adına şu parametrelerin varsayılan değerlerini değiştirebiliriz:\n",
    "- n_estimators: 100\n",
    "- max_depth: 3\n",
    "- learning_rate: 0.1\n",
    "- min_samples_split: 2\n",
    "- subsample: 1.0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4eda3dd9",
   "metadata": {},
   "source": [
    "Her bir parametre için bu değerleri de içeren ve bu değerlere yakın parametre listeleri oluşturup en iyilerini bulmaya çalışacağız."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed440f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'n_estimators'        : [50, 100, 150, 500, 750, 1000],\n",
    "              'max_depth'           : [1, 3, 5, 7, 10],\n",
    "              'learning_rate'       : [0.01, 0.05, 0.1],\n",
    "              'min_samples_split'   : [0.1, 0.3, 0.5, 0.7, 0.8, 1.0],\n",
    "              'subsample'           : [0.5, 0.7, 1.0]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890eda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making an object grid_GBC for GridSearchCV and fitting the dataset i.e X and y\n",
    "grid = GridSearchCV(estimator=gbr_model,    # Model object\n",
    "                    param_grid = parameters,\n",
    "                    cv = 2,     # Number of folds for Cross Validation \n",
    "                    n_jobs=-1)  # Use all processors to maximize performance\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c9ec28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are using print statements to print the results. It will give the values of hyperparameters as a result.\n",
    "print(\" - - - - Results from Grid Search - - - - \" )\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "341d3f5d",
   "metadata": {},
   "source": [
    "**Bulunan En İyi Parametre Değerleri**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e2ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeli en iyi parametre değerleri ile tekrar fit edelim\n",
    "gbr_model.set_params(**grid.best_params_).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa877831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bakalım yeni parametreler modelimize uygulanmış mı\n",
    "gbr_model.get_params()  # BİNGO !"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2aa14ba5",
   "metadata": {},
   "source": [
    "### 4. Final Model Başarı Değerlendirme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "599a61c9",
   "metadata": {},
   "source": [
    "Bakalım yaptığımız değişiklikler model başarısını nasıl etkilemiş"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7da2472",
   "metadata": {},
   "source": [
    "**RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.sqrt(-cross_val_score(gbr_model,\n",
    "                                 X,                     # Bağımsız değişkenler\n",
    "                                 y,                     # Bağımlı değişken\n",
    "                                 cv=5,\n",
    "                                 scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0ea9e83",
   "metadata": {},
   "source": [
    "**R Kare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d68d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(gbr_model,\n",
    "                        X_test,         # Bağımsız değişkenler\n",
    "                        y_test,         # Bağımlı değişken\n",
    "                        cv=5,\n",
    "                        scoring='r2'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a424c7b1",
   "metadata": {},
   "source": [
    "### 5. Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setinden rasgele bir gözlem birimi seçelim\n",
    "ran_obs = df.sample(1)\n",
    "ran_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hedef değişken hariç diğerlerine ait gözlem değerlerini alalım\n",
    "ran_obs_ind = ran_obs.loc[:, df.columns != 'SALARY_AVG_TL']\n",
    "ran_obs_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu gözlem birimi için tahmin işlemi yapalım\n",
    "pred_val = int(gbr_model.predict(ran_obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları mukayese edelim\n",
    "print(f\"ACTUAL VALUE\\t: {int(ran_obs['SALARY_AVG_TL'].values)}\")\n",
    "print(f\"PREDICTED VALUE\\t: {pred_val}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75a8acf0",
   "metadata": {},
   "source": [
    "Son olarak gerçek değerler ile tahmin değerlerini ayrı bir veri setinde birleştirelim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()   # Yeni bir df tanımla\n",
    "df_final[\"ACTUAL_AVG_TL\"] = df[\"SALARY_AVG_TL\"]     # Gerçek değerleri bir değişken olarak ekle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aea871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tüm gözlem birimleri için tahmin işlemi yapıp sonuçları sakla\n",
    "y_pred_all = gbr_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setine bu tahmin değerlerini ikinci bir değişken olarak ekle\n",
    "df_final[\"PREDICTED_AVG_TL\"] = y_pred_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8309c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu veri setinden rasgele 20 gözlemlik bir örneklem al, indekse göre sıralayarak göster\n",
    "df_final.sample(20).sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33a224f0",
   "metadata": {},
   "source": [
    "### 6. Sonuç"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f7dbefb",
   "metadata": {},
   "source": [
    "İlk haliyle başarı oranı (R-Kare skoru) %54 olan modelimizi hiperparametre optimizasyonu yaparak %61'e çıkardık.\n",
    "\n",
    "Her ne kadar bir model için düşük başarı skorları gibi görünse de hedef değişkenimizin sürekli sayısal bir değer olduğu ve bağımsız değişkenlerin onu temsil etmede çok çelişkili davrandığı düşünüldüğünde kayda değer bir skor olduğu anlaşılabilir."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e1d9410",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## D) LIGHTGBM REGRESSOR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2eb0b806",
   "metadata": {},
   "source": [
    "**What is LightGBM?**\n",
    "\n",
    "The LightGBM is short for Light Gradient Boosting Machine. It is a supervised boosting algorithm that works in a similar way as the XGBoost algorithm does but with some advanced features that makes it more powerful and fast.\n",
    "\n",
    "Similar to the XGBoost algorithm, we don’t need to handle the NULL value explicitly in the data preprocessing step while using the LightGBM algorithm as it also handles NULL values automatically.\n",
    "\n",
    "Other important features that make LightGBM different from other boosting algorithms is that it uses a histogram-based algorithm for the splitting of nodes and Gradient-Based One Side Sampling (GOSS) for the sampling."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ece7bd1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 1. Model Kurma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfde1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = LGBMRegressor().fit(X_train, y_train)    # Modeli train seti üzerinde fit et\n",
    "\n",
    "y_pred = lgbm_model.predict(X_test)                   # Test seti için tahmin iste\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a51fc372",
   "metadata": {},
   "source": [
    "### 2. İlk Model Başarısını Değerlendirme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d46584ef",
   "metadata": {},
   "source": [
    "The best way to see the performance of the model is to visualize the actual and the predicted values. We will use the matplotlib module to visualize the actual and the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5b4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# actual values\n",
    "plt.plot([i for i in range(len(y_test))], y_test, c='g', label=\"Gerçek Değerler\")\n",
    "\n",
    "# predicted values\n",
    "plt.plot([i for i in range(len(y_test))], y_pred, c='m', label=\"Tahmin Değerleri\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9be5ede",
   "metadata": {},
   "source": [
    "**Train Seti RMSE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a5766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_model.predict(X_train)\n",
    "np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5787db50",
   "metadata": {},
   "source": [
    "**Train Seti R-Kare**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc98375",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model.score(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8fe79fa",
   "metadata": {},
   "source": [
    "**Test Seti RMSE Değeri**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c19843",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3e6dbdf9",
   "metadata": {},
   "source": [
    "**Test Seti R-Kare Skoru**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a564c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. YOL\n",
    "# print(lgbm_model.score(X_test, y_test))\n",
    "\n",
    "# 2. YOL\n",
    "print('R score is :', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd73ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(cross_val_score(lgbm_model,\n",
    "                        X_test,              # Bağımsız değişkenler\n",
    "                        y_test,              # Bağımlı değişken\n",
    "                        cv=5,\n",
    "                        scoring='r2'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb6509dd",
   "metadata": {},
   "source": [
    "### 3. Hiperparametre Optimizasyonu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8994121e",
   "metadata": {},
   "source": [
    "Let us also create a validation function that will validate the models based on the cross-validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780d40a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for the validation of model\n",
    "def evaluate_model(model, Input, Output):\n",
    "    \n",
    "    # defining the method of validation\n",
    "    cv = RepeatedKFold(n_splits=10, n_repeats=3)\n",
    "    \n",
    "    # validating the model based on the accuracy score\n",
    "    r_square = cross_val_score(model, Input, Output, scoring='r2', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    # returning the accuracy score\n",
    "    return r_square"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc04e966",
   "metadata": {},
   "source": [
    "**GridSearchCV in LightGBM to get optimum values for parameters**\n",
    "\n",
    "GridSearchCV is an algorithm that takes different values for the specified parameters and then returns the optimum combinations. Let us apply the GridSearchCV to find the optimum values for parameters in LightGBM.\n",
    "\n",
    "Let us first create a LightGBM model and then initialize a range of values for different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff66809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a dict of grids\n",
    "grid = dict()\n",
    "\n",
    "# values for iteration\n",
    "grid['n_estimators'] = [10, 25, 50, 75, 100, 300, 500, 700, 1000]\n",
    "\n",
    "# values for learning rate\n",
    "grid['learning_rate'] = [0.01, 0.03, 0.05, 0.06, 0.07, 0.08, 0.1, 1.0]\n",
    "\n",
    "# values for the sample\n",
    "grid['subsample'] = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "\n",
    "# values for the depth of tree\n",
    "grid['max_depth'] = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04da684d",
   "metadata": {},
   "source": [
    "Let us now use the GridSearchCV to find the optimum values for the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7760fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the cv\n",
    "cv = RepeatedKFold(n_repeats=3)\n",
    "\n",
    "# applying the gridsearchcv method\n",
    "grid_search = GridSearchCV(estimator=lgbm_model, param_grid=grid, n_jobs=-1, cv=cv, scoring='r2')\n",
    "\n",
    "# storing the values\n",
    "grid_result = grid_search.fit(X, y)\n",
    "\n",
    "# printing the best parameters\n",
    "print(\"Accuracy score: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "# Accuracy score: 0.632873 using {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 1000, 'subsample': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63165de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bulunan en iyi parametre değerleri\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60eef67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu yeni parametrelerle final modelimizi oluşturalım\n",
    "lgbm_final = lgbm_model.set_params(**grid_result.best_params_).fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5b354805",
   "metadata": {},
   "source": [
    "### 4. Final Model Başarı Değerlendirme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7057054c",
   "metadata": {},
   "source": [
    "Bakalım yaptığımız değişiklikler model başarısını nasıl etkilemiş"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba3b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "np.mean(np.sqrt(-cross_val_score(lgbm_final,\n",
    "                                 X_test,                     # Bağımsız değişkenler\n",
    "                                 y_test,      # Bağımlı değişken\n",
    "                                 cv=5,\n",
    "                                 scoring=\"neg_mean_squared_error\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41143a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-Kare\n",
    "np.mean(cross_val_score(lgbm_final,\n",
    "                        X_test,                      # Bağımsız değişkenler\n",
    "                        y_test,       # Bağımlı değişken\n",
    "                        cv=5,\n",
    "                        scoring='r2'))\n",
    "# 0.63"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a424c7b1",
   "metadata": {},
   "source": [
    "### 5. Tahmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setinden rasgele bir gözlem birimi seçelim\n",
    "ran_obs = df.sample(1)\n",
    "ran_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3bc0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hedef değişken hariç diğerlerine ait gözlem değerlerini alalım\n",
    "ran_obs_ind = ran_obs.loc[:, df.columns != 'SALARY_AVG_TL']\n",
    "ran_obs_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b064158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu gözlem birimi için tahmin işlemi yapalım\n",
    "pred_val = int(lgbm_final.predict(ran_obs_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4258e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sonuçları mukayese edelim\n",
    "print(f\"ACTUAL VALUE\\t: {int(ran_obs['SALARY_AVG_TL'].values)}\")\n",
    "print(f\"PREDICTED VALUE\\t: {pred_val}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "52016f1b",
   "metadata": {},
   "source": [
    "# SON İŞLEMLER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6dad706c",
   "metadata": {},
   "source": [
    "## ACTUAL VS PREDICTED"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "75a8acf0",
   "metadata": {},
   "source": [
    "Gerçek değerler ile tahmin değerlerini ayrı bir veri setinde birleştirelim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd14a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()   # Yeni bir df tanımla\n",
    "df_final[\"ACTUAL_AVG_TL\"] = df[\"SALARY_AVG_TL\"]     # Gerçek değerleri bir değişken olarak ekle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aea871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tüm gözlem birimleri için tahmin işlemi yapıp sonuçları sakla\n",
    "y_pred_all = lgbm_final.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6587eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri setine bu tahmin değerlerini ikinci bir değişken olarak ekle\n",
    "df_final[\"PREDICTED_AVG_TL\"] = y_pred_all\n",
    "df_final[\"PREDICTED_AVG_TL\"] = df_final[\"PREDICTED_AVG_TL\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8309c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bu veri setinden rasgele 20 gözlemlik bir örneklem al, indekse göre sıralayarak göster\n",
    "df_final.sample(20).sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9e0bbf32",
   "metadata": {},
   "source": [
    "## MODEL DOSYASI OLUŞTURMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c2cd81",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
